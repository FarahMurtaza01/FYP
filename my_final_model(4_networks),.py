# -*- coding: utf-8 -*-
"""My Final_Model(4 Networks),.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qmTtoHLhSXygDZZ4cBRDuEd_yNXq58al
"""



from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.svm import SVC
from scipy.stats import skew, kurtosis
from sklearn.ensemble import RandomForestClassifier
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import (
    Input, Conv1D, MaxPooling1D, Flatten,
    LSTM, Bidirectional, Dense,
    Dropout, BatchNormalization, Concatenate
)
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import classification_report, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
from itertools import cycle
from google.colab import drive

# ---------------------------------------
# 1. Mount Drive & Load Dataset
# ---------------------------------------
drive.mount('/content/drive', force_remount=True)
data = pd.read_csv("/content/drive/MyDrive/slide_window_preprocessed_wesad.csv")

# ---------------------------------------
# ---------------------------------------
# 3. Verify & Encode Stress Levels
# ---------------------------------------
# Map numerical labels to stress levels based on the dataset description or knowledge
label_mapping = {1.0: 'Baseline', 2.0: 'Stress', 3.0: 'Amusement'}
data['Stress_Level'] = data['Label'].map(label_mapping)

# Drop rows with NaN in 'Stress_Level' before verification
data.dropna(subset=['Stress_Level'], inplace=True)


required_labels = {'Baseline', 'Stress', 'Amusement'}
found = set(data['Stress_Level'].unique())
if found != required_labels:
    raise ValueError(f"Expected labels {required_labels}, but found {found}")
le = LabelEncoder()
data['Stress_Label'] = le.fit_transform(data['Stress_Level'])
print("Label mapping:", dict(zip(le.classes_, le.transform(le.classes_))))

# ---------------------------------------
# 4. Prepare Features & Sliding Windows
# ---------------------------------------
features = ['EDA_mean', 'EDA_std', 'EDA_min', 'EDA_max', 'Temp_mean', 'Temp_std', 'Temp_min', 'Temp_max', 'ECG_mean', 'ECG_std', 'ECG_min', 'ECG_max', 'EMG_mean', 'EMG_std', 'EMG_min', 'EMG_max', 'Resp_mean', 'Resp_std', 'Resp_min', 'Resp_max']
X = data[features].values
y = data['Stress_Label'].values

# Standardize features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Build windows
time_steps = 10
X_seq, y_seq = [], []
for i in range(len(X) - time_steps):
    X_seq.append(X[i : i + time_steps])
    y_seq.append(y[i + time_steps])
X_seq = np.array(X_seq, dtype=np.float32)
y_seq = np.array(y_seq, dtype=np.int32)

# Split: train / val+test, then val+test â†’ val & test
X_train, X_tmp, y_train, y_tmp = train_test_split(
    X_seq, y_seq, test_size=0.2, random_state=42, stratify=y_seq
)
X_val, X_test, y_val, y_test = train_test_split(
    X_tmp, y_tmp, test_size=0.5, random_state=42, stratify=y_tmp
)

# ---------------------------------------
# 5. Callbacks & Hyperparameters
# ---------------------------------------
callbacks = [
    EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True),
    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=1e-6)
]
learning_rate = 1e-5
clip_norm = 1.0
drop_rate = 0.2
input_shape = X_train.shape[1:]  # (time_steps, n_features)
n_classes = len(le.classes_)

# ---------------------------------------
# 6. Model Builders

# Import Random Forest and evaluation tools
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.model_selection import train_test_split

# Define features for traditional models (Random Forest and SVM)
features_trad = ['EDA_mean', 'EDA_std', 'EDA_min', 'EDA_max', 'Temp_mean', 'Temp_std', 'Temp_min', 'Temp_max', 'ECG_mean', 'ECG_std', 'ECG_min', 'ECG_max', 'EMG_mean', 'EMG_std', 'EMG_min', 'EMG_max', 'Resp_mean', 'Resp_std', 'Resp_min', 'Resp_max']
X_trad = data[features_trad].values
y_trad = data['Stress_Label'].values

# Split data for traditional models (Random Forest and SVM)
X_train_trad, X_test_trad, y_train_trad, y_test_trad = train_test_split(X_trad, y_trad, test_size=0.2, random_state=42, stratify=y_trad)

#Random Forest


# Initialize and train Random Forest
rf_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)

rf_model.fit(X_train_trad, y_train_trad)

# Predict
y_pred_rf = rf_model.predict(X_test_trad)

# Evaluate
print("ðŸŽ¯ Random Forest Results:")
accuracy_rf = accuracy_score(y_test_trad, y_pred_rf)
print("Accuracy:", accuracy_rf)
print("\nClassification Report:\n", classification_report(y_test_trad, y_pred_rf))
print("Confusion Matrix:\n", confusion_matrix(y_test_trad, y_pred_rf))


#SVM


# ---------------------------------------

#2: CNN

def build_cnn(input_shape, n_classes):
    m = Sequential([
        Conv1D(64, 3, padding='same', activation='relu', input_shape=input_shape),
        BatchNormalization(),
        MaxPooling1D(2),

        Conv1D(128, 3, padding='same', activation='relu'),
        BatchNormalization(),
        MaxPooling1D(2),

        Flatten(),
        Dense(64, activation='relu'),
        BatchNormalization(),
        Dropout(drop_rate),

        Dense(n_classes, activation='softmax')
    ], name='CNN')
    return m

#3 BILSTM

def build_bilstm(input_shape, n_classes):
    m = Sequential([
        Bidirectional(LSTM(64, return_sequences=True), input_shape=input_shape),
        Dropout(drop_rate),

        Bidirectional(LSTM(32)),
        Dropout(drop_rate),

        Dense(16, activation='relu'),
        BatchNormalization(),
        Dropout(drop_rate),

        Dense(n_classes, activation='softmax')
    ], name='BiLSTM')
    return m

# Hybrid CNN-BILSTM

def build_hybrid(input_shape, n_classes):
    # Parallel CNN & BiLSTM branches on the raw input
    inp = Input(shape=input_shape, name='input_layer')

    # CNN branch
    x1 = Conv1D(64, 3, padding='same', activation='relu')(inp)
    x1 = BatchNormalization()(x1)
    x1 = Conv1D(128, 3, padding='same', activation='relu')(x1)
    x1 = BatchNormalization()(x1)
    x1 = MaxPooling1D(2)(x1)              # time_stepsâ†’time_steps/2
    x1 = Flatten()(x1)

    # BiLSTM branch
    x2 = Bidirectional(LSTM(128, return_sequences=False))(inp)
    x2 = Dropout(drop_rate)(x2)

    # Fuse
    x = Concatenate()([x1, x2])
    x = Dense(64, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Dropout(drop_rate)(x)
    out = Dense(n_classes, activation='softmax')(x)

    return Model(inputs=inp, outputs=out, name='Hybrid_CNN_BiLSTM')

def compile_and_train(model):
    model.compile(
        optimizer=Adam(learning_rate=learning_rate, clipnorm=clip_norm),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    print(f"\n>>> Training {model.name}")
    history = model.fit(
        X_train, y_train,
        epochs=40, batch_size=32,
        validation_data=(X_val, y_val),
        callbacks=callbacks,
        verbose=2
    )
    return model, history


# ---------------------------------------
def evaluate(model):
    probs = model.predict(X_test, verbose=0)
    preds = np.argmax(probs, axis=1)
    acc = accuracy_score(y_test, preds)
    print(f"\n{model.name} Results:")
    print(f"  Test Accuracy: {acc:.4f}")
    print(classification_report(
        y_test, preds,
        target_names=le.classes_,
        digits=4
    ))
    return acc, preds



# ---------------------------------------
# 7. Train & Compare
# ---------------------------------------
cnn = build_cnn(input_shape, n_classes)
cnn, cnn_history = compile_and_train(cnn)
acc_c, cnn_preds = evaluate(cnn)

bilstm = build_bilstm(input_shape, n_classes)
bilstm, bilstm_history = compile_and_train(bilstm)
acc_b, bilstm_preds = evaluate(bilstm)

hybrid = build_hybrid(input_shape, n_classes)
hybrid, hybrid_history = compile_and_train(hybrid)
acc_h, hybrid_preds = evaluate(hybrid)




print("\n=== Comparative Accuracy ===")
print(f"CNN:    {acc_c:.4f}")
print(f"BiLSTM: {acc_b:.4f}")
print(f"Hybrid: {acc_h:.4f}")
print(f"RF:     {accuracy_rf:.4f}")

if acc_h > max(acc_c, acc_b, accuracy_rf):
    print("âœ” The Hybrid model outperforms all baselines.")
elif accuracy_rf > max(acc_c, acc_b):
    print("âœ” The Random Forest model outperforms both baselines.")
# elif accuracy_svm > max(acc_c, acc_b):
#     print("âœ” The SVM model outperforms both baselines.")
else:
    print("âš  None of the models clearly outperform the othersâ€”consider further tuning.")



# 14. Plotting: Training History & Data Distributions
# ---------------------------
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

plt.figure(figsize=(24, 18))

# ----- 1. Hybrid Model -----
# Loss
plt.subplot(3, 4, 1)
plt.plot(hybrid_history.history['loss'], label='Training Loss')
plt.plot(hybrid_history.history['val_loss'], label='Validation Loss')
plt.title('Hybrid - Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Accuracy
plt.subplot(3, 4, 2)
plt.plot(hybrid_history.history['accuracy'], label='Training Acc')
plt.plot(hybrid_history.history['val_accuracy'], label='Validation Acc')
plt.title('Hybrid - Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Confusion Matrix
plt.subplot(3, 4, 3)
cm = confusion_matrix(y_test, hybrid_preds)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)
disp.plot(cmap='Blues', ax=plt.gca(), colorbar=False)
plt.title('Hybrid - Confusion Matrix')

# ----- 2. CNN Model -----
# Loss
plt.subplot(3, 4, 5)
plt.plot(cnn_history.history['loss'], label='Training Loss')
plt.plot(cnn_history.history['val_loss'], label='Validation Loss')
plt.title('CNN - Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Accuracy
plt.subplot(3, 4, 6)
plt.plot(cnn_history.history['accuracy'], label='Training Acc')
plt.plot(cnn_history.history['val_accuracy'], label='Validation Acc')
plt.title('CNN - Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Confusion Matrix
plt.subplot(3, 4, 7)
cm = confusion_matrix(y_test, cnn_preds)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)
disp.plot(cmap='Greens', ax=plt.gca(), colorbar=False)
plt.title('CNN - Confusion Matrix')

# ----- 3. BiLSTM Model -----
# Loss
plt.subplot(3, 4, 9)
plt.plot(bilstm_history.history['loss'], label='Training Loss')
plt.plot(bilstm_history.history['val_loss'], label='Validation Loss')
plt.title('BiLSTM - Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Accuracy
plt.subplot(3, 4, 10)
plt.plot(bilstm_history.history['accuracy'], label='Training Acc')
plt.plot(bilstm_history.history['val_accuracy'], label='Validation Acc')
plt.title('BiLSTM - Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Confusion Matrix
plt.subplot(3, 4, 11)
cm = confusion_matrix(y_test, bilstm_preds)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)
disp.plot(cmap='Oranges', ax=plt.gca(), colorbar=False)
plt.title('BiLSTM - Confusion Matrix')

# ----- 4. Random Forest Model (Only Confusion Matrix) -----
plt.subplot(3, 4, 12)
cm = confusion_matrix(y_test_trad, y_pred_rf)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)
disp.plot(cmap='Purples', ax=plt.gca(), colorbar=False)
plt.title('Random Forest - Confusion Matrix')

plt.tight_layout()
plt.show()

print("ðŸ“¦ CNN Parameters:", cnn.count_params())
print("âœ… CNN Final Validation Accuracy:", cnn_history.history['val_accuracy'][-1])

print("ðŸ“¦ BiLSTM Parameters:", bilstm.count_params())
print("âœ… BiLSTM Final Validation Accuracy:", bilstm_history.history['val_accuracy'][-1])

print("ðŸ“¦ Hybrid CNN-BiLSTM Parameters:", hybrid.count_params())
print("âœ… Hybrid Final Validation Accuracy:", hybrid_history.history['val_accuracy'][-1])