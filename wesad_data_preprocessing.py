# -*- coding: utf-8 -*-
"""WESAD_Data_Preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11zWrA7IzEIZkJ9RDq-GZgOBZrp3MpWu2
"""



import os
import pickle
import numpy as np
import matplotlib.pyplot as plt
from collections import defaultdict
import pandas as pd  #to save the data

def load_data(path, subject):
    """
    Load WESAD dataset for a single subject.
    use WESAD/SX/*.pkl files (X can be 2-17 there is no 12)
    Parameters:
    - path (str): Base directory containing subject folders.
    - subject (str): Subject folder name (e.g., 'S2').

    Returns:
    - data (dict): Loaded data dictionary from the subject's .pkl file.
    """
    file_path = os.path.join(path, subject, f"{subject}.pkl")
    with open(file_path, 'rb') as file:
        data = pickle.load(file, encoding='latin1')  # latin1 ensures compatibility with Python 3
    return data

class ReadDataOneSubject:
    """
    Class to load and access sensor data from a single subject in the WESAD dataset.

    Attributes:
    - data (dict): Full data loaded from the subject's .pkl file.
    - keys (list): Top-level keys in the WESAD data dict ['label', 'subject', 'signal'].
    - signal_keys (list): Subkeys under 'signal', typically ['wrist', 'chest'].
    - chest_sensor_keys (list): Sensor channels available for chest device.
    - wrist_sensor_keys (list): Sensor channels available for wrist device.
    """

    def __init__(self, path, subject):
        """
        Initialize and load the subject's data.

        Parameters:
        - path (str): Base directory path containing subject folders.
        - subject (str): Subject ID or folder name (e.g., 'S2').
        """
        self.keys = ['label', 'subject', 'signal']
        self.signal_keys = ['wrist', 'chest']
        self.chest_sensor_keys = ['ACC', 'ECG', 'EDA', 'EMG', 'Resp', 'Temp']
        self.wrist_sensor_keys = ['ACC', 'BVP', 'EDA', 'TEMP']

        file_path = os.path.join(path, subject, f"{subject}.pkl")
        with open(file_path, 'rb') as file:
            self.data = pickle.load(file, encoding='latin1')

    def get_labels(self):
        """
        Retrieve label sequence for the subject.

        Returns:
        - labels (np.ndarray): An array of integer labels indicating emotional states.
        """
        return self.data[self.keys[0]]

    def get_wrist_data(self):
        """
        Access wrist sensor data (not used in current processing pipeline).

        Prints available wrist sensor channels.

        Returns:
        - wrist_data (dict): Dictionary of wrist sensor data, keys like 'ACC', 'BVP', etc.
        """
        signal = self.data[self.keys[2]]
        wrist_data = signal[self.signal_keys[0]]
        print("Wrist data keys:", list(wrist_data.keys()))
        #wrist_ACC = wrist_data[self.wrist_sensor_keys[0]]
        #wrist_ECG = wrist_data[self.wrist_sensor_keys[1]]
        return wrist_data

    def get_chest_data(self):
        """
        Access chest sensor data (used for main analysis).

        Prints available chest sensor channels.

        Returns:
        - chest_data (dict): Dictionary of chest sensor data, keys like 'ECG', 'EDA', etc.
        """
        signal = self.data[self.keys[2]]
        chest_data = signal[self.signal_keys[1]]
        print("Chest data keys:", list(chest_data.keys()))
        return chest_data


def extract_fixed_mean_std_features(ecg_data, block=700):
    """
    Segments ECG/(or any other) data into non-overlapping blocks and extracts basic statistical features
    (mean, standard deviation, min, max) from each block.

    Parameters:
    - ecg_data (np.ndarray): 1D array of ECG signal values.
    - block (int): Number of samples in each block. Default is 700.

    Returns:
    - one_set (np.ndarray): 2D array of shape (num_blocks, 4) where each row contains:
        [mean, std, min, max] for one block.
    """

    num_blocks = len(ecg_data) // block  # Only consider full blocks
    mean_features = np.empty(num_blocks, dtype=np.float64)
    std_features = np.empty(num_blocks, dtype=np.float64)
    max_features = np.empty(num_blocks, dtype=np.float64)
    min_features = np.empty(num_blocks, dtype=np.float64)

    for idx in range(num_blocks):
        start = idx * block
        end = start + block
        segment = ecg_data[start:end]

        mean_features[idx] = np.mean(segment)
        std_features[idx] = np.std(segment)
        min_features[idx] = np.min(segment)
        max_features[idx] = np.max(segment)

    features = {'mean':mean_features, 'std':std_features, 'min':min_features, 'max':max_features}
    # Combine all features into a single array
    one_set = np.column_stack((mean_features, std_features, min_features, max_features))
    return one_set


#################### based on paper CNN-LSTM  ###############
###https://ceur-ws.org/Vol-3335/DLQ_short2.pdf

def extract_windowed_mean_std_features(ecg_data, sampling_rate=700):
    """
    Extracts mean, std, min, max features from ECG using overlapping windows.

    Parameters:
    - ecg_data: 1D NumPy array of ECG signal
    - sampling_rate: samples per second (Hz), e.g., 700 Hz

    Returns:
    - one_set: 2D NumPy array with shape (num_windows, 4)
    """

    # Convert seconds to samples
    window_sec = 5
    shift_sec = 2
    window_size = int(window_sec * sampling_rate)
    shift = int(shift_sec * sampling_rate)

    # Calculate number of windows
    num_windows = int((len(ecg_data) - window_size) / shift) + 1

    # Preallocate feature arrays
    mean_features = np.empty(num_windows)
    std_features = np.empty(num_windows)
    max_features = np.empty(num_windows)
    min_features = np.empty(num_windows)

    # Sliding window loop
    for idx in range(num_windows):
        start = idx * shift
        end = start + window_size
        window = ecg_data[start:end]

        mean_features[idx] = np.mean(window)
        std_features[idx] = np.std(window)
        max_features[idx] = np.max(window)
        min_features[idx] = np.min(window)

    # Stack features
    one_set = np.column_stack((mean_features, std_features, min_features, max_features))
    return one_set


def extract_one(chest_data_dict, idx, l_condition=0, feature_func=extract_fixed_mean_std_features):
    """
    Extracts statistical features (mean, std, min, max) from multiple physiological signals
    for a given time window index, and attaches the label.

    Parameters:
    - chest_data_dict (dict): Dictionary containing chest sensor signals.
                              Expected keys: 'ECG', 'EDA', 'Resp', 'EMG', 'Temp'
    - idx (int): Index of the time window to extract from each signal.
    - l_condition (int): Label value to assign to all rows (default is 0).
    - feature_func: fix or slide window for features default =fixed
    Generalized feature extractor that accepts a feature extraction function.

    Returns:
    - baseline_data (np.ndarray): 2D array of shape (num_blocks, total_features + 1).
        Final column is the label.
    """

    # Extract and flatten signals for the specified index
    ecg_data = chest_data_dict["ECG"][idx].flatten()
    emg_data = chest_data_dict["EMG"][idx].flatten()
    eda_data = chest_data_dict["EDA"][idx].flatten()
    temp_data = chest_data_dict["Temp"][idx].flatten()
    resp_data = chest_data_dict["Resp"][idx].flatten()

    # Compute features for each signal
    ecg_features = feature_func(ecg_data)
    emg_features = feature_func(emg_data)
    eda_features = feature_func(eda_data)
    temp_features = feature_func(temp_data)
    resp_features = feature_func(resp_data)

    # Concatenate all(or 4 of the) features horizontally
    baseline_data = np.hstack((eda_features, temp_features, ecg_features, emg_features, resp_features))

    # Create label array with same number of rows as feature blocks
    label_array = np.full((baseline_data.shape[0],), l_condition)

    # Append label as the final column
    baseline_data = np.column_stack((baseline_data, label_array))

    return baseline_data

def recur_print(obj):
    """
    Recursively prints the keys of a nested dictionary.

    Parameters:
    - obj (any): Input object to examine. Should be a dictionary or contain nested dictionaries.
    """
    if isinstance(obj, dict):
        print(obj.keys())
        for k in obj:
            recur_print(obj[k])

############### Obtain the data and save in csv file:

def save_to_csv(data, filename="preprocessed_wesad.csv"):
    columns = [
        "EDA_mean", "EDA_std", "EDA_min", "EDA_max",
        "Temp_mean", "Temp_std", "Temp_min", "Temp_max",
        "ECG_mean", "ECG_std", "ECG_min", "ECG_max",
        "EMG_mean", "EMG_std", "EMG_min", "EMG_max",
        "Resp_mean", "Resp_std", "Resp_min", "Resp_max",
        "Label"
    ]
    df = pd.DataFrame(data, columns=columns)
    df.to_csv(filename, index=False)




def plot_feature_distribution(data, num_blocks=100):
    """
    Visualizes the extracted features from the WESAD dataset as a heatmap.

    Shows up to `num_blocks` blocks per class (baseline, stress, amusement) and
    labels each row with the corresponding signal and feature type.

    Parameters:
    - data (np.ndarray): Output from `execute()` (shape: [n_samples, 21])
    - num_blocks (int): Max number of feature blocks to show per class
    """

    # Separate features and labels
    features = data[:, :-1]
    labels = data[:, -1]

    # Feature labels (for y-axis)
    signals = ['EDA', 'Temp', 'ECG', 'EMG', 'Resp']
    feature_types = ['Mean', 'Std', 'Min', 'Max']
    row_labels = [f"{sig}_{stat}" for sig in signals for stat in feature_types]

    # Prepare subplots
    fig, axs = plt.subplots(1, 3, figsize=(20, 8), sharey=True)

    for i, condition in enumerate([1, 2, 3]):
        condition_mask = np.where(labels == condition)[0][:num_blocks]
        condition_features = features[condition_mask].T  # shape: (20, N_blocks)

        ax = axs[i]
        im = ax.imshow(condition_features, aspect='auto', cmap='viridis')

        ax.set_title(['Baseline', 'Stress', 'Amusement'][i], fontsize=14)
        ax.set_xlabel("Block Index")
        ax.set_xticks(np.linspace(0, condition_features.shape[1]-1, min(10, condition_features.shape[1])).astype(int))

        # Only show feature names on leftmost subplot
        if i == 0:
            ax.set_yticks(np.arange(len(row_labels)))
            ax.set_yticklabels(row_labels, fontsize=10)
        else:
            ax.set_yticks([])

        # Add colorbar
        cbar = plt.colorbar(im, ax=ax)
        cbar.set_label("Feature Value", rotation=270, labelpad=15)

    fig.suptitle("🧠 Feature Heatmap per Condition\n(Each row = Mean/Std/Min/Max per signal)", fontsize=16)
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()


def plot_signal_histograms(data):
    """
    Plots histograms of all 5 physiological signals (EDA, Temp, ECG, EMG, Resp)
    across all feature blocks in the dataset.

    Parameters:
    - data (np.ndarray): Output of `execute()` or loaded CSV (shape: [n_samples, 21])
    - normalized (bool): If True, use standard axis limits; otherwise adapt per feature
    """
    # Signal feature indices
    signal_names = ['EDA', 'Temp', 'ECG', 'EMG', 'Resp']
    feature_types = ['Mean', 'Std', 'Min', 'Max']

    fig, axs = plt.subplots(5, 4, figsize=(20, 15))
    fig.suptitle("Histogram of Extracted Features for Each Signal", fontsize=20)

    for i in range(5):  # For each signal
        for j in range(4):  # For each feature type
            idx = i * 4 + j
            ax = axs[i, j]
            ax.hist(data[:, idx], bins=50, color='skyblue', edgecolor='black')
            ax.set_title(f"{signal_names[i]} - {feature_types[j]}")
            ax.grid(True)

    plt.tight_layout(rect=[0, 0, 1, 0.96])
    plt.show()


def execute():
    """
    Loads, processes, and extracts features from the WESAD dataset for multiple subjects.

    For each subject:
    - Loads chest sensor data.
    - Identifies indices of baseline (1), stress (2), and amusement (3)  segments.
    - Extracts mean/std/min/max features from each signal (ECG, EDA, EMG, Temp, Resp).
    - Labels the feature blocks accordingly.
    - Returns a full dataset for all subjects stacked together.

    Returns:
    - data (np.ndarray): A NumPy array with shape (n_samples, n_features + 1),
                         where the last column is the label (1 = baseline, 2 = stress, 3 = amusement).
    """

    data_set_path = "/content/drive/MyDrive/uni_siegen_dataset/WESAD"  #change here
    subject_ids = [11, 13, 14, 15] #change here

    all_data = {}
    all_data_sliding = {}

    for sid in subject_ids:
        subject = f"S{sid}"
        print(f"\n➡️  Reading data for subject: {subject}")

        # here we call our class
        obj_data = ReadDataOneSubject(data_set_path, subject)

        labels = obj_data.get_labels()
        chest_data_dict = obj_data.get_chest_data()

        print("Chest data lengths:", {k: len(v) for k, v in chest_data_dict.items()})

        # Identify segments by label type
        baseline_idxs = np.where(labels == 1)[0]
        stress_idxs = np.where(labels == 2)[0]
        amusement_idxs = np.where(labels == 3)[0]

        print(f"  Baseline: {len(baseline_idxs)} | Stress: {len(stress_idxs)} | Amusement: {len(amusement_idxs)}")

        # Extract features from each labeled segment # Fixed block
        baseline_data = extract_one(chest_data_dict, baseline_idxs, l_condition=1, feature_func=extract_fixed_mean_std_features)
        stress_data = extract_one(chest_data_dict, stress_idxs, l_condition=2, feature_func=extract_fixed_mean_std_features)
        amusement_data = extract_one(chest_data_dict, amusement_idxs, l_condition=3, feature_func=extract_fixed_mean_std_features)


        # Stack all conditions for the subject
        full_subject_data = np.vstack((baseline_data, stress_data, amusement_data))
        print(f"  ✅ Subject data shape: {full_subject_data.shape}")

        all_data[subject] = full_subject_data


        # Sliding window case  maybe better
        base_sliding = extract_one(chest_data_dict, baseline_idxs, l_condition=1, feature_func=extract_windowed_mean_std_features)
        stress_sliding = extract_one(chest_data_dict, stress_idxs, l_condition=2, feature_func=extract_windowed_mean_std_features)
        amuse_sliding = extract_one(chest_data_dict, amusement_idxs, l_condition=3, feature_func=extract_windowed_mean_std_features)
        all_data_sliding[subject] = np.vstack((base_sliding, stress_sliding, amuse_sliding))



    # Combine all subjects into one dataset
    final_data = np.vstack(list(all_data.values()))
    print(f"\n✅ Final dataset shape (all subjects): {final_data.shape}")

    #for sliding window case
    final_sliding = np.vstack(list(all_data_sliding.values()))
    print(f"\n✅with sliding window case: final dataset shape (all subjects): {final_data.shape}")
    return final_data, final_sliding



if __name__ == '__main__':
    execute()
    data, slide_data = execute()
    slide_data.shape

    plot_feature_distribution(data, num_blocks=100)  # Visualize 100 blocks per condition
    save_to_csv(data)
    save_to_csv(slide_data, filename="slide_window_preprocessed_wesad.csv")
    plot_signal_histograms(slide_data)
    """
    ecg, eda = chest_data_dict['ECG'], chest_data_dict['EDA']
    x = [i for i in range(len(baseline))]
    for one in baseline:
        x = [i for i in range(99)]
        plt.plot(x, ecg[one:100])
        break
    """
    print("Read data file")
    #Flow: Read data for all subjects -> Extract features (Preprocessing) -> Train the model